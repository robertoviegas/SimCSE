{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "wikipedia.set_lang(\"pt\")\n",
    "\n",
    "PASTA_DESTINO = r'C:\\Users\\Administrator\\Desktop\\Repositórios\\SimCSE\\textos_wikipedia'\n",
    "os.makedirs(PASTA_DESTINO, exist_ok=True)\n",
    "\n",
    "# Garante que o nome do arquivo seja válido\n",
    "def limpar_nome_arquivo(nome):\n",
    "    return re.sub(r\"[^\\w\\s-]\", \"\", nome).strip().replace(\" \", \"_\") + \".txt\"\n",
    "\n",
    "def contar_total_linhas_txt(diretorio):\n",
    "    total_linhas = 0\n",
    "    total_arquivos = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(diretorio):\n",
    "        for nome_arquivo in files:\n",
    "            if nome_arquivo.endswith(\".txt\"):\n",
    "                caminho_arquivo = os.path.join(root, nome_arquivo)\n",
    "                try:\n",
    "                    with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
    "                        linhas = f.readlines()\n",
    "                        total_linhas += len([l for l in linhas if l.strip()])\n",
    "                        total_arquivos += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao ler {caminho_arquivo}: {e}\")\n",
    "    return total_linhas\n",
    "\n",
    "# Salva frases de uma página, retorna o número de frases\n",
    "def processar_pagina(titulo):\n",
    "    wikipedia.set_lang(\"pt\")\n",
    "    try:\n",
    "        conteudo = wikipedia.page(titulo).content\n",
    "        conteudo = re.split(r\"==+\\s*(Ligações externas|Referências|Ver também|Bibliografia)\\s*==+\", conteudo)[0]\n",
    "        # Remove subtítulos do tipo === Seção === ou == Seção ==\n",
    "        conteudo = re.sub(r\"^={2,}.*?={2,}$\", \"\", conteudo, flags=re.MULTILINE)      \n",
    "        # Tokeniza em frases\n",
    "        frases = sent_tokenize(conteudo, language=\"portuguese\")\n",
    "        # Remove frases que só contêm espaços, tabs ou caracteres invisíveis\n",
    "        frases = [re.sub(r\"\\s+\", \" \", f.strip()) for f in frases if f.strip() and not re.match(r\"^={2,}.*={2,}$\", f.strip())]\n",
    "        if len(frases) < 3:\n",
    "            return 0  # ignora textos muito curtos\n",
    "\n",
    "        nome_arquivo = limpar_nome_arquivo(titulo)\n",
    "        caminho = os.path.join(PASTA_DESTINO, nome_arquivo)\n",
    "\n",
    "        with open(caminho, \"w\", encoding=\"utf-8\") as f:\n",
    "            for frase in frases:\n",
    "                f.write(frase + \"\\n\")\n",
    "        return len(frases)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar '{titulo}': {e}\")\n",
    "        # pass\n",
    "        # sys.exit(1)\n",
    "        return 0\n",
    "# Obtém títulos aleatórios relacionados\n",
    "def expandir_titulos(temas_base, limite=5000):\n",
    "    titulos = set()\n",
    "    for tema in temas_base:\n",
    "        try:\n",
    "            relacionados = wikipedia.search(tema, results=500)\n",
    "            titulos.update(relacionados)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if len(titulos) >= limite:\n",
    "            break\n",
    "    return list(titulos)\n",
    "\n",
    "def save_list_to_txt(data_list, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for item in data_list:\n",
    "            file.write(str(item) + '\\n')\n",
    "\n",
    "# Geração e salvamento de frases\n",
    "def coletar_frases_ate_limite(temas_base,meta_frases=1_000_000, n_jobs=-1):\n",
    "    total_frases = contar_total_linhas_txt(PASTA_DESTINO)\n",
    "    while total_frases < meta_frases:\n",
    "        titulos_processados = []\n",
    "        for _,_, temas in os.walk(PASTA_DESTINO):\n",
    "            for temaa in temas:\n",
    "                titulos_processados.append(temaa.replace('.txt',''))\n",
    "        titulos_processados = [t.replace('_',' ') for t in titulos_processados]\n",
    "\n",
    "        for tema in tqdm(temas_base):\n",
    "            candidatos = sorted(expandir_titulos([tema], limite=1000))            \n",
    "            candidatos = [t for t in candidatos if t not in titulos_processados]\n",
    "            print(f\"Processando {len(candidatos)} títulos para '{tema}'\") # len()\n",
    "\n",
    "            resultados = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(processar_pagina)(titulo) for titulo in candidatos\n",
    "            )\n",
    "            total_frases += sum(resultados)\n",
    "            print(f\"Total de frases coletadas: {total_frases}\")\n",
    "            if tema==temas_base[-1]:\n",
    "                print(f\"\\n✅ Coleta finalizada com {total_frases} frases.\")\n",
    "                sys.exit(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def concatenate_txt_files(directory, output_file):\n",
    "    # Abre o arquivo de saída em modo de escrita\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        # Itera sobre todos os arquivos no diretório\n",
    "        for filename in os.listdir(directory):\n",
    "            # Verifica se o arquivo tem a extensão .txt\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                # Abre o arquivo .txt em modo de leitura\n",
    "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                    # Lê o conteúdo do arquivo e escreve no arquivo de saída\n",
    "                    outfile.write(infile.read())\n",
    "                    # Adiciona uma linha em branco entre os arquivos\n",
    "                    outfile.write('\\n')\n",
    "\n",
    "# Exemplo de uso\n",
    "concatenate_txt_files(PASTA_DESTINO, 'arquivo_geral.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file(input_file, output_file):\n",
    "    # Abre o arquivo de entrada para leitura e o arquivo de saída para escrita\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        # Itera sobre cada linha do arquivo de entrada\n",
    "        for line in infile:\n",
    "            # Remove espaços em branco no início e no final da linha\n",
    "            stripped_line = line.strip()\n",
    "            # Verifica se a linha não está vazia e não contém a palavra 'displaystyle'\n",
    "            keywords = ['displaystyle', 'textstyle', 'sqrt', 'fract','=','Γ', 'Δ', 'Ε', 'Ζ', 'Η', 'Θ',\n",
    "                        'Ι', 'Κ', 'Λ', 'Μ', 'Ν', 'Ξ', 'Ο', 'Π', 'Ρ',\n",
    "                        'Σ', 'Τ', 'Υ', 'Φ', 'Χ', 'Ψ', 'Ω','alpha', 'gamma', 'epsilon', 'zeta', 'theta',\n",
    "                        'iota', 'kappa', 'lambda', 'omicron','rho',\n",
    "                        'sigma','upsilon', 'phi','φ']\n",
    "            if all(keyword not in stripped_line for keyword in keywords) and len(stripped_line)>50:\n",
    "                # Se nenhuma das strings estiver presente em stripped_line, execute o código aqui\n",
    "                outfile.write(line)\n",
    "                \n",
    "\n",
    "# Exemplo de uso\n",
    "clean_file('arquivo_geral.txt', 'arquivo_limpo.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando 177 títulos para 'Ciência'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:11<08:10, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 766015\n",
      "Processando 181 títulos para 'História'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2/42 [00:25<08:37, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 790099\n",
      "Processando 210 títulos para 'Tecnologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/42 [00:39<08:39, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 799525\n",
      "Processando 201 títulos para 'Educação'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/42 [00:52<08:30, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 809251\n",
      "Processando 232 títulos para 'Geografia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/42 [01:07<08:37, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 818892\n",
      "Processando 287 títulos para 'Matemática'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6/42 [01:25<09:07, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 826769\n",
      "Processando 193 títulos para 'Física'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/42 [01:38<08:22, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 833784\n",
      "Processando 219 títulos para 'Brasil'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [01:53<08:20, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 852704\n",
      "Processando 202 títulos para 'Saúde'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 9/42 [02:07<07:56, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 860438\n",
      "Processando 186 títulos para 'Economia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/42 [02:20<07:28, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 872551\n",
      "Processando 192 títulos para 'Literatura'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11/42 [02:32<07:00, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 878706\n",
      "Processando 205 títulos para 'Arte'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 12/42 [02:46<06:50, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 895245\n",
      "Processando 197 títulos para 'Política'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 13/42 [03:03<06:59, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 917157\n",
      "Processando 185 títulos para 'Religião'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14/42 [03:17<06:46, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 927529\n",
      "Processando 251 títulos para 'Música'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 15/42 [03:34<06:47, 15.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 943978\n",
      "Processando 247 títulos para 'Cinema'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 16/42 [03:49<06:34, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 949583\n",
      "Processando 234 títulos para 'Esportes'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 17/42 [04:04<06:18, 15.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 961319\n",
      "Processando 197 títulos para 'Meio ambiente'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 18/42 [04:18<05:50, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 978295\n",
      "Processando 291 títulos para 'Biologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 19/42 [04:35<05:55, 15.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 985206\n",
      "Processando 251 títulos para 'Química'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20/42 [04:50<05:40, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 991420\n",
      "Processando 254 títulos para 'Filosofia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 21/42 [05:06<05:27, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1005205\n",
      "Processando 211 títulos para 'Sociologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 22/42 [05:20<05:02, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1018852\n",
      "Processando 251 títulos para 'Psicologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 23/42 [05:36<04:48, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1029780\n",
      "Processando 250 títulos para 'Astronomia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24/42 [05:51<04:32, 15.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1035200\n",
      "Processando 217 títulos para 'Direito'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 25/42 [06:06<04:15, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1048220\n",
      "Processando 226 títulos para 'Engenharia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [06:20<03:59, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1054619\n",
      "Processando 221 títulos para 'Antropologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 27/42 [06:35<03:42, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1062028\n",
      "Processando 288 títulos para 'Computação'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 28/42 [06:52<03:39, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1069716\n",
      "Processando 239 títulos para 'Ecologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 29/42 [07:08<03:24, 15.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1078470\n",
      "Processando 213 títulos para 'Medicina'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 30/42 [07:22<02:59, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1083214\n",
      "Processando 231 títulos para 'Linguística'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [07:36<02:42, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1089666\n",
      "Processando 273 títulos para 'Arquitetura'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 32/42 [07:53<02:34, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1099234\n",
      "Processando 353 títulos para 'Mitologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 33/42 [08:14<02:33, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1109532\n",
      "Processando 207 títulos para 'Guerra'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 34/42 [08:29<02:12, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1144693\n",
      "Processando 204 títulos para 'Agricultura'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 35/42 [08:42<01:47, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1152033\n",
      "Processando 218 títulos para 'Climatologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 36/42 [08:56<01:29, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1166871\n",
      "Processando 195 títulos para 'Demografia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 37/42 [09:08<01:10, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1173775\n",
      "Processando 203 títulos para 'Genética'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 38/42 [09:21<00:55, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1183846\n",
      "Processando 224 títulos para 'Robótica'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 39/42 [09:36<00:42, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1200982\n",
      "Processando 203 títulos para 'Educação física'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 40/42 [09:49<00:27, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1208993\n",
      "Processando 244 títulos para 'Paleontologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [10:04<00:14, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1215028\n",
      "Processando 257 títulos para 'Geologia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [10:20<00:15, 15.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases coletadas: 1220899\n",
      "\n",
      "✅ Coleta finalizada com 1220899 frases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "temas_base = [\n",
    "    \"Ciência\", \"História\", \"Tecnologia\", \"Educação\", \"Geografia\",\n",
    "    \"Matemática\", \"Física\", \"Brasil\", \"Saúde\", \"Economia\", \"Literatura\",\n",
    "    \"Arte\", \"Política\", \"Religião\", \"Música\", \"Cinema\", \"Esportes\",\n",
    "    \"Meio ambiente\", \"Biologia\", \"Química\", \"Filosofia\", \"Sociologia\",\n",
    "    \"Psicologia\", \"Astronomia\", \"Direito\", \"Engenharia\", \"Antropologia\",\n",
    "    \"Computação\", \"Ecologia\", \"Medicina\", \"Linguística\", \"Arquitetura\",\n",
    "    \"Mitologia\", \"Guerra\", \"Agricultura\", \"Climatologia\", \"Demografia\",\n",
    "    \"Genética\", \"Robótica\", \"Educação física\", \"Paleontologia\", \"Geologia\"\n",
    "]\n",
    "coletar_frases_ate_limite(temas_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de arquivos .txt: 995\n",
      "Total de frases (linhas não vazias): 134118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "134118"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos_processados = []\n",
    "for _,_, temas in os.walk(r'C:\\Users\\Administrator\\Desktop\\Repositórios\\SimCSE\\textos_wikipedia'):\n",
    "    for temaa in temas:\n",
    "        titulos_processados.append(temaa.replace('.txt',''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simcse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
